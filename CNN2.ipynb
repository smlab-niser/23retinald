{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essential libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your training, validation, and testing folders\n",
    "train_folder = \"Original Images/a. Training Set\"\n",
    "valid_folder = \"Original Images/b. Validation Set\"\n",
    "test_folder = \"Original Images/c. Testing Set\"\n",
    "\n",
    "# Set the paths to your training, validation, and testing CSV files for labels\n",
    "train_labels_file = \"Groundtruths/training28.csv\"\n",
    "valid_labels_file = \"Groundtruths/validation28.csv\"\n",
    "test_labels_file = \"Groundtruths/testing28.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files for labels\n",
    "train_labels = pd.read_csv(train_labels_file)\n",
    "valid_labels = pd.read_csv(valid_labels_file)\n",
    "test_labels = pd.read_csv(test_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "img_width, img_height = 100, 100\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with image filenames and labels\n",
    "train_df = pd.read_csv(train_labels_file)\n",
    "valid_df = pd.read_csv(valid_labels_file)\n",
    "test_df = pd.read_csv(test_labels_file)\n",
    "\n",
    "# Remove rows from dataframes where filenames are missing\n",
    "missing_rows = [1506,1505,1744,1752,1753,1756,1762,1770,1781,1788,1792,1842,1846,1873,1878] \n",
    "train_df.drop(missing_rows, inplace=True)\n",
    "missing_rows = [549,550,552,560,590,596]\n",
    "valid_df.drop(missing_rows, inplace=True)\n",
    "missing_rows = [553,590,592,564,614,617,622,624,628]\n",
    "test_df.drop(missing_rows, inplace=True)\n",
    "\n",
    "# Add the .png extension to the filenames\n",
    "train_df['ID'] = train_df['ID'].apply(lambda x: str(x) + '.png')\n",
    "valid_df['ID'] = valid_df['ID'].apply(lambda x: str(x) + '.png')\n",
    "test_df['ID'] = test_df['ID'].apply(lambda x: str(x) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator object with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5])\n",
    "\n",
    "# Create flow generators for the training set and validation set\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_folder,\n",
    "    x_col='ID',\n",
    "    y_col=train_df.columns[2:],\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw')\n",
    "\n",
    "# Create flow generators for the validation set\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    directory=valid_folder,\n",
    "    x_col='ID',\n",
    "    y_col=valid_df.columns[2:],\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw')\n",
    "\n",
    "\n",
    "# Create flow generators for the testing set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_folder,\n",
    "    x_col='ID',\n",
    "    y_col=valid_df.columns[2:],\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 16)        1216      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 32)        12832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 22, 22, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 18, 18, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 64)          102464    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210,748\n",
      "Trainable params: 210,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(28, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using fit_generator\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy and loss values\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=test_steps)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.ravel(), y_pred.ravel())\n",
    "\n",
    "# plot precision-recall curve\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
