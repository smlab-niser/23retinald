{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "img_width, img_height = 200, 200\n",
    "target_size = (200,200)\n",
    "batch_size = 28\n",
    "epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your training, validation, and testing folders\n",
    "train_folder = \"Original Images/a. Training Set\"\n",
    "valid_folder = \"Original Images/b. Validation Set\"\n",
    "test_folder = \"Original Images/c. Testing Set\"\n",
    "\n",
    "# Set the paths to your training, validation, and testing CSV files for labels\n",
    "train_labels_file = \"Groundtruths/training28.csv\"\n",
    "valid_labels_file = \"Groundtruths/validation28.csv\"\n",
    "test_labels_file = \"Groundtruths/testing28.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  DR  MH  ODC  TSLN  DN  MYA  ARMD  BRVO  ODP  ...  AH  MS  EDN  RT  \\\n",
      "0  1.png   1   0    0     0   0    0     0     0    0  ...   0   0    0   0   \n",
      "1  2.png   1   0    0     0   0    0     0     0    0  ...   0   0    0   0   \n",
      "2  3.png   1   0    0     0   0    0     0     0    0  ...   0   0    0   0   \n",
      "3  4.png   0   1    1     0   0    0     0     0    0  ...   0   0    0   0   \n",
      "4  5.png   1   0    0     0   0    0     0     0    0  ...   0   0    0   0   \n",
      "\n",
      "   ERM  PT  MHL  RP  TV  ST  \n",
      "0    0   0    0   0   0   0  \n",
      "1    0   0    0   0   0   0  \n",
      "2    0   0    0   0   0   0  \n",
      "3    0   0    0   0   0   0  \n",
      "4    0   0    0   0   0   0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DR', 'MH', 'ODC', 'TSLN', 'DN', 'MYA', 'ARMD', 'BRVO', 'ODP',\n",
       "       'ODE', 'LS', 'RS', 'CSR', 'OTHER', 'CRS', 'CRVO', 'RPEC', 'AION', 'AH',\n",
       "       'MS', 'EDN', 'RT', 'ERM', 'PT', 'MHL', 'RP', 'TV', 'ST'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file with image filenames and labels\n",
    "train_labels_df = pd.read_csv(train_labels_file)\n",
    "valid_labels_df = pd.read_csv(valid_labels_file)\n",
    "test_labels_df = pd.read_csv(test_labels_file)\n",
    "\n",
    "# Remove rows from dataframes where filenames are missing\n",
    "missing_rows = [1506,1505,1744,1752,1753,1756,1762,1770,1781,1788,1792,1842,1846,1873,1878] \n",
    "train_labels_df.drop(missing_rows, inplace=True)\n",
    "missing_rows = [549,550,552,560,590,596]\n",
    "valid_labels_df.drop(missing_rows, inplace=True)\n",
    "missing_rows = [553,590,592,564,614,617,622,624,628]\n",
    "test_labels_df.drop(missing_rows, inplace=True)\n",
    "\n",
    "# Add the .png extension to the filenames\n",
    "train_labels_df['ID'] = train_labels_df['ID'].apply(lambda x: str(x) + '.png')\n",
    "valid_labels_df['ID'] = valid_labels_df['ID'].apply(lambda x: str(x) + '.png')\n",
    "test_labels_df['ID'] = test_labels_df['ID'].apply(lambda x: str(x) + '.png')\n",
    "\n",
    "# Calculate the number of positive cases in each label except the ID column\n",
    "label_counts = train_labels_df.iloc[:, 1:].sum(axis=0)\n",
    "\n",
    "# Sort the labels in descending order by number of positive cases\n",
    "sorted_labels = label_counts.sort_values(ascending=False)\n",
    "\n",
    "# Reorder the columns in train_df, valid_df, and test_df using the sorted label order\n",
    "train_labels_df = train_labels_df[['ID'] + list(sorted_labels.index)]\n",
    "valid_labels_df = valid_labels_df[['ID'] + list(sorted_labels.index)]\n",
    "test_labels_df = test_labels_df[['ID'] + list(sorted_labels.index)]\n",
    "\n",
    "#Dropping disease risk label\n",
    "train_labels_df = train_labels_df.drop('Disease_Risk', axis=1)\n",
    "valid_labels_df = valid_labels_df.drop('Disease_Risk', axis=1)\n",
    "test_labels_df = test_labels_df.drop('Disease_Risk', axis=1)\n",
    "\n",
    "# Print the updated dataframe to verify the sorting\n",
    "print(train_labels_df.head())\n",
    "train_labels_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Get the last 15 labels as minority labels\n",
    "minority_labels = list(train_labels_df.columns[-15:])\n",
    "\n",
    "# Create a minority_df that contains only the minority labels and the ID column\n",
    "minority_df = train_labels_df[['ID'] + minority_labels]\n",
    "\n",
    "# Shuffle the minority_df to avoid having batches of only one label\n",
    "minority_df = shuffle(minority_df, random_state=42)\n",
    "\n",
    "# Define the rescaling generator\n",
    "rescale_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define ImageDataGenerator for augmentation\n",
    "aug_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# create class weight dictionary\n",
    "class_weights = {label: (len(train_labels_df)/train_labels_df[label].sum()) for label in minority_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1905 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset using flow_from_dataframe\n",
    "train_generator = rescale_datagen.flow_from_dataframe(\n",
    "    dataframe=train_labels_df,\n",
    "    directory=train_folder,\n",
    "    x_col=\"ID\",\n",
    "    y_col=train_labels_df.columns[1:],\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DR', 'MH', 'ODC', 'TSLN', 'DN', 'MYA', 'ARMD', 'BRVO', 'ODP', 'ODE', 'LS', 'RS', 'CSR'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Deependra Singh\\python\\Retinal-Disease-Classification\\ResNet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a generator for the minority_df that applies augmentation to minority labels\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m minority_augmented_generator \u001b[39m=\u001b[39m aug_datagen\u001b[39m.\u001b[39;49mflow_from_dataframe(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataframe\u001b[39m=\u001b[39;49mminority_df,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     directory\u001b[39m=\u001b[39;49mtrain_folder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     x_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mID\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y_col\u001b[39m=\u001b[39;49mtrain_labels_df\u001b[39m.\u001b[39;49mcolumns[\u001b[39m1\u001b[39;49m:],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     target_size\u001b[39m=\u001b[39;49m(img_height, img_width),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weights)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:1806\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m   1800\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1801\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1802\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1803\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1804\u001b[0m     )\n\u001b[1;32m-> 1806\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameIterator(\n\u001b[0;32m   1807\u001b[0m     dataframe,\n\u001b[0;32m   1808\u001b[0m     directory,\n\u001b[0;32m   1809\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1810\u001b[0m     x_col\u001b[39m=\u001b[39;49mx_col,\n\u001b[0;32m   1811\u001b[0m     y_col\u001b[39m=\u001b[39;49my_col,\n\u001b[0;32m   1812\u001b[0m     weight_col\u001b[39m=\u001b[39;49mweight_col,\n\u001b[0;32m   1813\u001b[0m     target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1814\u001b[0m     color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1815\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1816\u001b[0m     class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1817\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1818\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1819\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1820\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1821\u001b[0m     save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1822\u001b[0m     save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1823\u001b[0m     save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1824\u001b[0m     subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1825\u001b[0m     interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1826\u001b[0m     validate_filenames\u001b[39m=\u001b[39;49mvalidate_filenames,\n\u001b[0;32m   1827\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1828\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:993\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_targets \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39marray(df[col]\u001b[39m.\u001b[39mtolist()) \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m y_col]\n\u001b[0;32m    992\u001b[0m \u001b[39mif\u001b[39;00m class_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 993\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_targets \u001b[39m=\u001b[39m df[y_col]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    994\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilenames)\n\u001b[0;32m    995\u001b[0m validated_string \u001b[39m=\u001b[39m (\n\u001b[0;32m    996\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalidated\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m validate_filenames \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnon-validated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DR', 'MH', 'ODC', 'TSLN', 'DN', 'MYA', 'ARMD', 'BRVO', 'ODP', 'ODE', 'LS', 'RS', 'CSR'] not in index\""
     ]
    }
   ],
   "source": [
    "# Create a generator for the minority_df that applies augmentation to minority labels\n",
    "minority_augmented_generator = aug_datagen.flow_from_dataframe(\n",
    "    dataframe=minority_df,\n",
    "    directory=train_folder,\n",
    "    x_col=\"ID\",\n",
    "    y_col=train_labels_df.columns[1:],\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(img_height, img_width),\n",
    "    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1905 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df['ID'] = train_labels_df['ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Deependra Singh\\python\\Retinal-Disease-Classification\\ResNet.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m minority_tuple \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(labels_to_oversample)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m minority_df\u001b[39m=\u001b[39mtrain_labels_df[train_labels_df[\u001b[39mlist\u001b[39;49m(train_labels_df\u001b[39m.\u001b[39;49mcolumns)]\u001b[39m.\u001b[39;49misin(minority_tuple)]\u001b[39m.\u001b[39;49mloc[:, [\u001b[39m'\u001b[39;49m\u001b[39mID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mlist\u001b[39;49m(train_labels_df\u001b[39m.\u001b[39;49mcolumns)]]\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6065\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6062\u001b[0m     keyarr \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[0;32m   6064\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6065\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer_for(keyarr)\n\u001b[0;32m   6066\u001b[0m     keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(keyarr)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6052\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6034\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6035\u001b[0m \u001b[39mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   6036\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6049\u001b[0m \u001b[39marray([0, 2])\u001b[39;00m\n\u001b[0;32m   6050\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6051\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6052\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer(target)\n\u001b[0;32m   6053\u001b[0m indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   6054\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3973\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3969\u001b[0m     \u001b[39mreturn\u001b[39;00m this\u001b[39m.\u001b[39m_get_indexer(\n\u001b[0;32m   3970\u001b[0m         target, method\u001b[39m=\u001b[39mmethod, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance\n\u001b[0;32m   3971\u001b[0m     )\n\u001b[1;32m-> 3973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_indexer(target, method, limit, tolerance)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4000\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3997\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3998\u001b[0m         tgt_values \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39m_get_engine_target()\n\u001b[1;32m-> 4000\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_indexer(tgt_values)\n\u001b[0;32m   4002\u001b[0m \u001b[39mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:308\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5794\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "minority_tuple = tuple(labels_to_oversample)\n",
    "minority_df=train_labels_df[train_labels_df[list(train_labels_df.columns)].isin(minority_tuple)].loc[:, ['ID', list(train_labels_df.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All values in column x_col=ID must be strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Deependra Singh\\python\\Retinal-Disease-Classification\\ResNet.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a new generator that applies augmentation to minority labels\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m minority_augmented_generator \u001b[39m=\u001b[39m aug_datagen\u001b[39m.\u001b[39;49mflow_from_dataframe(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataframe\u001b[39m=\u001b[39;49mtrain_labels_df[train_labels_df[\u001b[39mlist\u001b[39;49m(train_labels_df\u001b[39m.\u001b[39;49mcolumns)]\u001b[39m.\u001b[39;49misin(labels_to_oversample\u001b[39m.\u001b[39;49mtolist())],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     directory\u001b[39m=\u001b[39;49mtrain_folder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     x_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mID\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y_col\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(train_labels_df\u001b[39m.\u001b[39;49mcolumns),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     target_size\u001b[39m=\u001b[39;49m(img_height, img_width),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weights\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Combine the rescaled and augmented generators using zip\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m train_generator \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(train_generator, minority_augmented_generator)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:1806\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m   1800\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1801\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1802\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1803\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1804\u001b[0m     )\n\u001b[1;32m-> 1806\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameIterator(\n\u001b[0;32m   1807\u001b[0m     dataframe,\n\u001b[0;32m   1808\u001b[0m     directory,\n\u001b[0;32m   1809\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1810\u001b[0m     x_col\u001b[39m=\u001b[39;49mx_col,\n\u001b[0;32m   1811\u001b[0m     y_col\u001b[39m=\u001b[39;49my_col,\n\u001b[0;32m   1812\u001b[0m     weight_col\u001b[39m=\u001b[39;49mweight_col,\n\u001b[0;32m   1813\u001b[0m     target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1814\u001b[0m     color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1815\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1816\u001b[0m     class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1817\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1818\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1819\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1820\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1821\u001b[0m     save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1822\u001b[0m     save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1823\u001b[0m     save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1824\u001b[0m     subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1825\u001b[0m     interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1826\u001b[0m     validate_filenames\u001b[39m=\u001b[39;49mvalidate_filenames,\n\u001b[0;32m   1827\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1828\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:968\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    967\u001b[0m \u001b[39m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params(df, x_col, y_col, weight_col, classes)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    970\u001b[0m     validate_filenames\n\u001b[0;32m    971\u001b[0m ):  \u001b[39m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:1030\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[39m# check that filenames/filepaths column values are all strings\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(df[x_col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))):\n\u001b[1;32m-> 1030\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1031\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll values in column x_col=\u001b[39m\u001b[39m{\u001b[39;00mx_col\u001b[39m}\u001b[39;00m\u001b[39m must be strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1033\u001b[0m \u001b[39m# check labels are string if class_mode is binary or sparse\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_mode \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "\u001b[1;31mTypeError\u001b[0m: All values in column x_col=ID must be strings."
     ]
    }
   ],
   "source": [
    "# Create a new generator that applies augmentation to minority labels\n",
    "minority_augmented_generator = aug_datagen.flow_from_dataframe(\n",
    "    dataframe=train_labels_df[train_labels_df[list(train_labels_df.columns)].isin(labels_to_oversample.tolist())],\n",
    "    directory=train_folder,\n",
    "    x_col='ID',\n",
    "    y_col=list(train_labels_df.columns),\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(img_height, img_width),\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Combine the rescaled and augmented generators using zip\n",
    "train_generator = zip(train_generator, minority_augmented_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 634 validated image filenames.\n",
      "Found 631 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create flow generators for the validation set\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_labels_df,\n",
    "    directory=valid_folder,\n",
    "    x_col='ID',\n",
    "    y_col=valid_labels_df.columns[1:],\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "# Create flow generators for the testing set\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_labels_df,\n",
    "    directory=test_folder,\n",
    "    x_col='ID',\n",
    "    y_col=valid_labels_df.columns[1:],\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Deependra Singh\\python\\Retinal-Disease-Classification\\ResNet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# apply oversampling to the train generator\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ros \u001b[39m=\u001b[39m RandomOverSampler()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m ros\u001b[39m.\u001b[39;49mfit_resample(train_generator[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m], train_generator[\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Deependra%20Singh/python/Retinal-Disease-Classification/ResNet.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_generator \u001b[39m=\u001b[39m (X_resampled, y_resampled)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:80\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_resample\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     check_classification_targets(y)\n\u001b[0;32m     81\u001b[0m     arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m     82\u001b[0m     X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py:199\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    188\u001b[0m     \u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    201\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    206\u001b[0m     ]:\n\u001b[0;32m    207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py:298\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[39mif\u001b[39;00m sparse_pandas:\n\u001b[0;32m    296\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be class \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseSeries\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseArray\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 298\u001b[0m \u001b[39mif\u001b[39;00m is_multilabel(y):\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m \u001b[39m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[39m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\multiclass.py:180\u001b[0m, in \u001b[0;36mis_multilabel\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    175\u001b[0m         \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mdata) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    176\u001b[0m         \u001b[39mor\u001b[39;00m (labels\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m (labels\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m labels))\n\u001b[0;32m    177\u001b[0m         \u001b[39mand\u001b[39;00m (y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m _is_integral_float(labels))  \u001b[39m# bool, int, uint\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m     labels \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39;49munique_values(y)\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(labels) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    183\u001b[0m         y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m _is_integral_float(labels)  \u001b[39m# bool, int, uint\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n\u001b[0;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Deependra Singh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    335\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# apply oversampling to the train generator\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(train_generator[0][0], train_generator[0][1])\n",
    "train_generator = (X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 634 validated image filenames.\n",
      "Found 631 validated image filenames.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the minority classes\n",
    "class_freq = labels.sum(axis=0)\n",
    "minority_classes = class_freq[class_freq < (class_freq.max() / 2)].index[-15:]\n",
    "\n",
    "# Create a dictionary of class weights to be used during training\n",
    "class_weights = {}\n",
    "for i, col in enumerate(labels.columns):\n",
    "    if col in minority_classes:\n",
    "        class_weights[i] = 'balanced'\n",
    "    else:\n",
    "        class_weights[i] = 1\n",
    "\n",
    "# Create a list of file paths to the images in the dataset\n",
    "filepaths = [os.path.join(image_dir_path, filename) for filename in labels.index]\n",
    "\n",
    "# Create a generator object to load the images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels,\n",
    "    directory=image_dir_path,\n",
    "    x_col='filename',\n",
    "    y_col=list(labels.columns),\n",
    "    target_size=image_size,\n",
    "    class_mode='raw',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create a pipeline object to oversample only the minority classes\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "oversampling_pipeline = Pipeline([('oversampler', oversampler)])\n",
    "\n",
    "# Apply the oversampling pipeline to the training set\n",
    "X_resampled, y_resampled = oversampling_pipeline.fit_resample(train_generator, train_generator.labels)\n",
    "\n",
    "# Reindex the DataFrame to match the resampled order\n",
    "resampled_labels = labels.iloc[X_resampled.index].reset_index(drop=True)\n",
    "\n",
    "# Create a generator object to load the resampled images\n",
    "resampled_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=resampled_labels,\n",
    "    directory=image_dir_path,\n",
    "    x_col='filename',\n",
    "    y_col=list(resampled_labels.columns),\n",
    "    target_size=image_size,\n",
    "    class_mode='raw',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Train the model using the resampled data and the class weights\n",
    "model.fit(resampled_generator, epochs=num_epochs, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create oversampler\n",
    "oversampler = RandomOverSampler()\n",
    "\n",
    "# Define function to load data and apply oversampling\n",
    "def load_data(folder, labels):\n",
    "    # Load images and labels using ImageDataGenerator\n",
    "    generator = train_datagen.flow_from_directory(\n",
    "        folder,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='raw',\n",
    "        shuffle=False)\n",
    "    # Get labels in the correct order\n",
    "    labels = labels.reindex(generator.filenames)\n",
    "    # Convert labels to numpy array\n",
    "    labels = labels.values\n",
    "    # Apply oversampling on minority classes\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(generator.filepaths, labels)\n",
    "    # Convert filepaths to numpy array\n",
    "    X_resampled = np.array(X_resampled)\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_resampled = keras.utils.to_categorical(y_resampled, num_classes=29)\n",
    "    # Shuffle the data\n",
    "    indices = np.arange(len(X_resampled))\n",
    "    np.random.shuffle(indices)\n",
    "    X_resampled = X_resampled[indices]\n",
    "    y_resampled = y_resampled[indices]\n",
    "    # Create generator for the oversampled data\n",
    "    generator = train_datagen.flow_from_dataframe(\n",
    "        pd.DataFrame({'filename': X_resampled, 'class': np.argmax(y_resampled, axis=1)}),\n",
    "        directory=folder,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Keras image data generators for training, validation, and test sets\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        rotation_range=20, \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1, \n",
    "        shear_range=0.1, \n",
    "        zoom_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class weights for the imbalanced dataset\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_labels_df['label']), train_labels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# read data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# code to read the data and labels\n",
    "\n",
    "# convert data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "labels = to_categorical(labels, num_classes=28)\n",
    "\n",
    "# split data into training, validation, and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=640, stratify=labels)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=640, stratify=train_labels)\n",
    "\n",
    "# compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_labels.argmax(axis=1)), train_labels.argmax(axis=1))\n",
    "\n",
    "# create undersampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# fit and transform undersampler on training data\n",
    "train_data, train_labels = undersample.fit_resample(train_data.reshape(-1, 640, 640, 3), train_labels.argmax(axis=1))\n",
    "train_labels = to_categorical(train_labels, num_classes=28)\n",
    "\n",
    "# create oversampler\n",
    "oversample = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# create image data generator for data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "\n",
    "# fit and transform oversampler on training data\n",
    "train_data, train_labels = oversample.fit_resample(train_data, train_labels)\n",
    "\n",
    "# create batches of augmented data\n",
    "train_generator = datagen.flow(train_data, train_labels, batch_size=32)\n",
    "\n",
    "# create validation and testing generators without data augmentation\n",
    "val_generator = ImageDataGenerator().flow(val_data, val_labels, batch_size=32)\n",
    "test_generator = ImageDataGenerator().flow(test_data, test_labels, batch_size=32)\n",
    "\n",
    "# create ResNet50 model and train on augmented data\n",
    "# code to create and train ResNet50 model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
