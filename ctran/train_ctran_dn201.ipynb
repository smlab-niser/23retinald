{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "from backbone1 import DenseNet201\n",
    "from dataloader import create_dataloader\n",
    "from metric import Metric\n",
    "from ctran import CTranEncoder\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set device to GPU if available, else use CPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Current device: {torch.cuda.get_device_name(torch.cuda.current_device())}\" if torch.cuda.is_available() else \"Current device: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 16\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0000001\n",
    "image_size = 384\n",
    "num_workers = 4\n",
    "num_labels = 20\n",
    "thresholds = [0.5] * num_labels\n",
    "num_classes = 20\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = create_dataloader(data_dir=data_dir, batch_size=batch_size, num_workers=num_workers, size=image_size, phase='train')\n",
    "val_dataloader = create_dataloader(data_dir=data_dir, batch_size=batch_size, num_workers=num_workers, size=image_size, phase='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deependra/project/rfmidc/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/deependra/project/rfmidc/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "backbone = DenseNet201(num_classes=num_classes, embed_dim = 960)\n",
    "model = CTranEncoder(num_classes=num_classes, embed_dim=960, num_layers=6, num_heads=num_workers, backbone=backbone)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:48<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.3308, ML mAP: 0.0862, ML F1: 0.0707, ML AUC: 0.5264, ML Score: 0.3063, Bin AUC: 0.5833, Model Score: 0.4448, Bin F1: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:15<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Epoch [1/2], Loss: 0.3308, ML mAP: 0.0718, ML F1: 0.0000, ML AUC: 0.5302, ML Score: 0.3010, Bin AUC: 0.5789, Model Score: 0.4400, Bin F1: 0.0000\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:49<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 0.3109, ML mAP: 0.1089, ML F1: 0.0000, ML AUC: 0.5793, ML Score: 0.3441, Bin AUC: 1.0000, Model Score: 0.6720, Bin F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:15<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Epoch [2/2], Loss: 0.3109, ML mAP: 0.0914, ML F1: 0.0000, ML AUC: 0.6144, ML Score: 0.3529, Bin AUC: 0.3684, Model Score: 0.3607, Bin F1: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Metric class\n",
    "metric = Metric(num_classes=num_classes)\n",
    "\n",
    "# create empty lists to store predicted probabilities and true labels for each epoch\n",
    "val_preds_all, val_labels_all = [], []\n",
    "\n",
    "# define the epochs at which to plot the ROC curve\n",
    "roc_epochs = [5,10,20,30,40,50,60,70,80,90,100,120,140,160,180,200]\n",
    "\n",
    "# create empty lists to store ROC data for each epoch\n",
    "roc_fpr = []\n",
    "roc_tpr = []\n",
    "roc_auc = []\n",
    "f1_arr = []\n",
    "loss_arr = []\n",
    "model_arr = []\n",
    "\n",
    "# Train and evaluate model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Train phase\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)    \n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        #print(outputs)\n",
    "        \n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics on train set\n",
    "        with torch.no_grad():\n",
    "            metric.update(outputs, labels,0)\n",
    "\n",
    "    # Print metrics on train set\n",
    "    ml_f1_score, map_score, auc_score, ml_map_score, ml_auc_score, ml_score, bin_auc, model_score, bin_f1_score = metric.compute(1)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, ML mAP: {ml_map_score:.4f}, ML F1: {ml_f1_score:.4f}, ML AUC: {ml_auc_score:.4f}, ML Score: {ml_score:.4f}, Bin AUC: {bin_auc:.4f}, Model Score: {model_score:.4f}, Bin F1: {bin_f1_score:.4f}\")\n",
    "\n",
    "    # Reset Metric class for evaluation\n",
    "    metric.reset()\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute metrics on validation set\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            metric.update(outputs, labels,1)\n",
    "            running_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # append the predicted probabilities and true labels to lists for calculating ROC AUC score later\n",
    "            val_preds += outputs.tolist()\n",
    "            val_labels += labels.tolist()\n",
    " \n",
    "        # Print metrics on validation set\n",
    "        ml_f1_score, map_score, auc_score, ml_map_score, ml_auc_score, ml_score, bin_auc, model_score, bin_f1_score = metric.compute(0)\n",
    "        print(f\"Val - Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, ML mAP: {ml_map_score:.4f}, ML F1: {ml_f1_score:.4f}, ML AUC: {ml_auc_score:.4f}, ML Score: {ml_score:.4f}, Bin AUC: {bin_auc:.4f}, Model Score: {model_score:.4f}, Bin F1: {bin_f1_score:.4f}\")\n",
    "        \n",
    "        f1_arr.append(ml_f1_score)\n",
    "        model_arr.append(model_score)\n",
    "        loss_arr.append(running_loss / len(val_dataloader))\n",
    "\n",
    "        # append the predicted probabilities and true labels for this epoch to the lists for all epochs\n",
    "        val_preds_all.append(val_preds)\n",
    "        val_labels_all.append(val_labels)\n",
    "\n",
    "        # check if the current epoch is in the list of epochs to plot ROC curve\n",
    "        if epoch+1 in roc_epochs:\n",
    "            # calculate ROC curve and AUC score for validation set\n",
    "            fpr, tpr, roc_thresholds = roc_curve(np.concatenate(val_labels_all).ravel(), np.concatenate(val_preds_all).ravel())\n",
    "            roc_fpr.append(fpr)\n",
    "            roc_tpr.append(tpr)\n",
    "            roc_auc.append(auc(fpr, tpr))\n",
    "\n",
    "        print() # empty line for spacing\n",
    "        \n",
    "        # Reset Metric class for next epoch\n",
    "        metric.reset()\n",
    "        del images\n",
    "        del labels\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfmidc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
